{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running Multiple Models in Parallel\n",
    "This notebook demonstrates AI inference on a video file and a webcam feed using DeGirum PySDK and Hailo hardware. The pipeline is built using DeGirum Tools Streams, enabling efficient video processing with AI models.\n",
    "\n",
    "Key Features:\n",
    "- Loads and runs two object detection models:\n",
    "- YOLOv8 COCO model on a traffic video.\n",
    "- YOLOv8 Face model on a live webcam feed.\n",
    "- Displays AI-detected objects with overlay and FPS metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import degirum as dg\n",
    "import degirum_tools\n",
    "import degirum_tools.streams as dgstreams\n",
    "\n",
    "inference_host_address = \"@local\"\n",
    "zoo_url = 'degirum/hailo'\n",
    "token=''\n",
    "device_type=['HAILORT/HAILO8L']\n",
    "\n",
    "# Define the configurations for video file and webcam\n",
    "configurations = [\n",
    "    {\n",
    "        \"model_name\": \"yolov8n_relu6_coco--640x640_quant_hailort_hailo8l_1\",\n",
    "        \"source\": \"../assets/Traffic.mp4\",  # Video file\n",
    "        \"display_name\": \"Traffic Camera\",\n",
    "    },\n",
    "    {\n",
    "        \"model_name\": \"yolov8n_relu6_face--640x640_quant_hailort_hailo8l_1\",\n",
    "        \"source\": 0,  # Webcam index\n",
    "        \"display_name\": \"Webcam Feed\",\n",
    "    },\n",
    "]\n",
    "\n",
    "# load models\n",
    "models = [\n",
    "    dg.load_model(\n",
    "        model_name=cfg[\"model_name\"], \n",
    "        inference_host_address=inference_host_address, \n",
    "        zoo_url=zoo_url, \n",
    "        token=token,\n",
    "        device_type=device_type\n",
    "    )\n",
    "    for cfg in configurations\n",
    "]\n",
    "\n",
    "# define gizmos\n",
    "sources = [dgstreams.VideoSourceGizmo(cfg[\"source\"]) for cfg in configurations]\n",
    "detectors = [dgstreams.AiSimpleGizmo(model) for model in models]\n",
    "display = dgstreams.VideoDisplayGizmo(\n",
    "    [cfg[\"display_name\"] for cfg in configurations], show_ai_overlay=True, show_fps=True\n",
    ")\n",
    "\n",
    "# create pipeline\n",
    "pipeline = (\n",
    "    (source >> detector for source, detector in zip(sources, detectors)),\n",
    "    (detector >> display[di] for di, detector in enumerate(detectors)),\n",
    ")\n",
    "\n",
    "# start composition\n",
    "dgstreams.Composition(*pipeline).start()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "supervision",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
