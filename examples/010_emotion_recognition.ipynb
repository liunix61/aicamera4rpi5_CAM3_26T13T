{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Emotion Recognition Inference with DeGirum PySDK</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook demonstrates an emotion recognition example where each detected face from video frames is individually analyzed to predict emotions. The combined results are then displayed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import degirum as dg, degirum_tools\n",
    "\n",
    "inference_host_address = \"@local\"\n",
    "zoo_url = 'degirum/hailo'\n",
    "token=''\n",
    "device_type=['HAILORT/HAILO8L']\n",
    "\n",
    "# specify model names\n",
    "face_det_model_name = \"yolov8n_relu6_face--640x640_quant_hailort_hailo8l_1\"\n",
    "emotion_cls_model_name = \"emotion_recognition_fer2013--64x64_quant_hailort_multidevice_1\"\n",
    "\n",
    "# specify video source\n",
    "video_source = \"../assets/faces_and_emotion.mp4\"\n",
    "\n",
    "# Load face detection and emotion detection models\n",
    "face_det_model = dg.load_model(\n",
    "    model_name=face_det_model_name,\n",
    "    inference_host_address=inference_host_address,\n",
    "    zoo_url=zoo_url,\n",
    "    token='',\n",
    "    device_type=device_type,\n",
    "    overlay_color=[(255,255,0),(0,255,0)]    \n",
    ")\n",
    "\n",
    "emotion_cls_model = dg.load_model(\n",
    "    model_name=emotion_cls_model_name,\n",
    "    inference_host_address=inference_host_address,\n",
    "    zoo_url=zoo_url,\n",
    "    token='',\n",
    "    device_type=device_type,\n",
    ")\n",
    "\n",
    "# Create a compound cropping model\n",
    "crop_model = degirum_tools.CroppingAndClassifyingCompoundModel(\n",
    "    face_det_model, \n",
    "    emotion_cls_model\n",
    ")\n",
    "\n",
    "# run AI inference on video stream\n",
    "inference_results = degirum_tools.predict_stream(crop_model, video_source)\n",
    "\n",
    "# display inference results\n",
    "# Press 'x' or 'q' to stop\n",
    "with degirum_tools.Display(\"Faces and Emotion\") as display:\n",
    "    for inference_result in inference_results:\n",
    "        display.show(inference_result.image_overlay)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
