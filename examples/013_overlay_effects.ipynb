{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ol6OT9TFOb04"
      },
      "source": [
        "# Image overlay properties using DeGirum PySDK\n",
        "In this notebook, we illustrate the different image overlay properties of DeGirum PySDK and how it can be used to display inference results with different types of formatting."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jos6h8WAsbMm"
      },
      "outputs": [],
      "source": [
        "import degirum as dg\n",
        "import degirum_tools\n",
        "\n",
        "# Define variables\n",
        "model_name = 'yolov8n_coco--640x640_quant_hailort_hailo8l_1'\n",
        "zoo_url = 'degirum/hailo'\n",
        "inference_host_address = '@local'\n",
        "device_type = 'HAILORT/HAILO8L'\n",
        "token = ''\n",
        "image_source = '../assets/dog_and_person.jpg'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load Model\n",
        "\n",
        "`model` object in DeGirum PySDK has a set of properties and methods that handles inference lifecycle tasks and also provides properties for overlay customization seperately. In this notebook, we will go through some of the examples reflecting overlay properties in PySDK.\n",
        "\n",
        "Required arguments for `dg.load_model` are model name, host address, model zoo url, cloud token and device type."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model = dg.load_model(\n",
        "    model_name=model_name,\n",
        "    inference_host_address=inference_host_address,\n",
        "    zoo_url=zoo_url,\n",
        "    token=token,\n",
        "    device_type=device_type\n",
        ")\n",
        "\n",
        "# perform AI model inference on given image source\n",
        "print(f\" Running inference using '{model_name}' on image source '{image_source}'\")\n",
        "inference_result = model(image_source)\n",
        "\n",
        "print('\\n Inference Results \\n', inference_result)  # numeric results\n",
        "\n",
        "# show results of inference\n",
        "with degirum_tools.Display(\"AI Camera\") as output_display:\n",
        "    output_display.show_image(inference_result)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ws6fbGizTBoZ"
      },
      "source": [
        "### Show Class Labels\n",
        "- Displays the class names (e.g., \"person\", \"car\") on top of detected objects in the overlay. Default value is `True`. Set to `False` to hide labels."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 932
        },
        "id": "ndB3pHzTS9PG",
        "outputId": "ff95a30a-be5f-4cd3-89f3-5b319767f7ee"
      },
      "outputs": [],
      "source": [
        "# load AI model\n",
        "model = dg.load_model(\n",
        "    model_name=model_name,\n",
        "    inference_host_address=inference_host_address,\n",
        "    zoo_url=zoo_url,\n",
        "    token=token,\n",
        "    device_type=device_type,\n",
        "    overlay_show_labels = False # set to True to show labels on the image \n",
        ")\n",
        "\n",
        "# perform AI model inference on given image source\n",
        "print(f\" Running inference using '{model_name}' on image source '{image_source}'\")\n",
        "inference_result = model(image_source)\n",
        "\n",
        "print('\\n Inference Results \\n', inference_result)  # numeric results\n",
        "\n",
        "# show results of inference\n",
        "with degirum_tools.Display(\"AI Camera\") as output_display:\n",
        "    output_display.show_image(inference_result)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NldiuBxITvHU"
      },
      "source": [
        "### Show Class Probabilities\n",
        "- Shows the prediction confidence score (e.g., 0.95) next to each detected label. Default value is `False`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 932
        },
        "id": "qCApHksETsun",
        "outputId": "61c2ca46-6754-4da3-be9f-20838c301ec7"
      },
      "outputs": [],
      "source": [
        "# load AI model\n",
        "model = dg.load_model(\n",
        "    model_name=model_name,\n",
        "    inference_host_address=inference_host_address,\n",
        "    zoo_url=zoo_url,\n",
        "    token=token,\n",
        "    device_type=device_type,\n",
        "    overlay_show_probabilities = True\n",
        ")\n",
        "\n",
        "# perform AI model inference on given image source\n",
        "print(f\" Running inference using '{model_name}' on image source '{image_source}'\")\n",
        "inference_result = model(image_source)\n",
        "\n",
        "print('\\n Inference Results \\n', inference_result)  # numeric results\n",
        "\n",
        "# show results of inference\n",
        "with degirum_tools.Display(\"AI Camera\") as output_display:\n",
        "    output_display.show_image(inference_result)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Abm_QcLITvTX"
      },
      "source": [
        "### Set Font Scale\n",
        "- Adjusts the size of the text displayed on the overlay (labels and probabilities). Its value is of type `float`, default being 1.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 932
        },
        "id": "mk9Op3IRTtD4",
        "outputId": "58108fb7-0400-4e77-e4c6-a1a501660dd6"
      },
      "outputs": [],
      "source": [
        "# load AI model\n",
        "model = dg.load_model(\n",
        "    model_name=model_name,\n",
        "    inference_host_address=inference_host_address,\n",
        "    zoo_url=zoo_url,\n",
        "    token=token,\n",
        "    device_type=device_type,\n",
        "    overlay_font_scale = 3.2\n",
        ")\n",
        "\n",
        "# perform AI model inference on given image source\n",
        "print(f\" Running inference using '{model_name}' on image source '{image_source}'\")\n",
        "inference_result = model(image_source)\n",
        "\n",
        "print('\\n Inference Results \\n', inference_result)  # numeric results\n",
        "\n",
        "# show results of inference\n",
        "with degirum_tools.Display(\"AI Camera\") as output_display:\n",
        "    output_display.show_image(inference_result)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OsWcx6DeTvkW"
      },
      "source": [
        "### Set Bounding Box Thickness\n",
        "- Changes the thickness of the boxes drawn around detected objects. Its value is of type `float`, default being 3.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 932
        },
        "id": "aFbuL00_TtbU",
        "outputId": "18144763-cc4b-4388-82aa-ef1e62742677"
      },
      "outputs": [],
      "source": [
        "# load AI model\n",
        "model = dg.load_model(\n",
        "    model_name=model_name,\n",
        "    inference_host_address=inference_host_address,\n",
        "    zoo_url=zoo_url,\n",
        "    token=token,\n",
        "    device_type=device_type,\n",
        "    overlay_line_width = 5\n",
        ")\n",
        "\n",
        "# perform AI model inference on given image source\n",
        "print(f\" Running inference using '{model_name}' on image source '{image_source}'\")\n",
        "inference_result = model(image_source)\n",
        "\n",
        "print('\\n Inference Results \\n', inference_result)  # numeric results\n",
        "\n",
        "\n",
        "# show results of inference\n",
        "with degirum_tools.Display(\"AI Camera\") as output_display:\n",
        "    output_display.show_image(inference_result)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0yuZ7yQ4Tya-"
      },
      "source": [
        "### Set Overlay Box Color\n",
        "- Defines the color of bounding boxes using RGB format. Default value is Black RGB(0,0,0).\n",
        "- overlay_color can also be `(list[tuple[int,int,int]])`: Palette of RGB colors for drawing results; each tuple is an (R, G, B) value.\n",
        "Color for a detection is chosen as `overlay_color[class_id % len(overlay_color)]` (class-ID modulo palette length)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 932
        },
        "id": "Kr_27UWcTt1p",
        "outputId": "0b7c8e31-9cfd-4f69-95bd-5a3d005a66d8"
      },
      "outputs": [],
      "source": [
        "# load AI model\n",
        "model = dg.load_model(\n",
        "    model_name=model_name,\n",
        "    inference_host_address=inference_host_address,\n",
        "    zoo_url=zoo_url,\n",
        "    token=token,\n",
        "    device_type=device_type,\n",
        "    overlay_color = [(255, 0, 0), (0, 255, 0), (0,0,255)] # red and green and blue colors\n",
        ")\n",
        "\n",
        "# perform AI model inference on given image source\n",
        "print(f\" Running inference using '{model_name}' on image source '{image_source}'\")\n",
        "inference_result = model(image_source)\n",
        "\n",
        "print('\\n Inference Results \\n', inference_result)  # numeric results\n",
        "\n",
        "\n",
        "# show results of inference\n",
        "with degirum_tools.Display(\"AI Camera\") as output_display:\n",
        "    output_display.show_image(inference_result)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ckcheAwwV-F5"
      },
      "source": [
        "### Set Overlay Transparency\n",
        "- Controls the transparency of the overlay bounding boxes that appears over the image. This value is a `float` ranging from 0 to 1, where 1 represents full opacity and 0 indicates near invisibility. Default value is 1.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 932
        },
        "id": "XRr5h1yuWq42",
        "outputId": "01cd114f-93bb-4526-eef2-1946861dab45"
      },
      "outputs": [],
      "source": [
        "# load AI model\n",
        "model = dg.load_model(\n",
        "    model_name=model_name,\n",
        "    inference_host_address=inference_host_address,\n",
        "    zoo_url=zoo_url,\n",
        "    token=token,\n",
        "    device_type=device_type,\n",
        "    overlay_alpha = 0.5 # 50% transparent overlay\n",
        ")\n",
        "\n",
        "# perform AI model inference on given image source\n",
        "print(f\" Running inference using '{model_name}' on image source '{image_source}'\")\n",
        "inference_result = model(image_source)\n",
        "\n",
        "print('\\n Inference Results \\n', inference_result)  # numeric results\n",
        "\n",
        "# show results of inference\n",
        "with degirum_tools.Display(\"AI Camera\") as output_display:\n",
        "    output_display.show_image(inference_result)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IWt6eWJdV9vq"
      },
      "source": [
        "### Blur Detected Objects\n",
        "- Applies a blur effect to each detected object in the overlay. You can specify particular object classes to blur, or use `\"all\"` to blur every detected object. The default value is `None`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 932
        },
        "id": "y0kHjT9AWrWI",
        "outputId": "fd5f894a-610a-4e60-909a-1f9045948ce6"
      },
      "outputs": [],
      "source": [
        "# load AI model\n",
        "model = dg.load_model(\n",
        "    model_name=model_name,\n",
        "    inference_host_address=inference_host_address,\n",
        "    zoo_url=zoo_url,\n",
        "    token=token,\n",
        "    device_type=device_type,\n",
        "    overlay_blur = \"dog\"\n",
        ")\n",
        "\n",
        "# perform AI model inference on given image source\n",
        "print(f\" Running inference using '{model_name}' on image source '{image_source}'\")\n",
        "inference_result = model(image_source)\n",
        "\n",
        "print('\\n Inference Results \\n', inference_result)  # numeric results\n",
        "\n",
        "# show results of inference\n",
        "with degirum_tools.Display(\"AI Camera\") as output_display:\n",
        "    output_display.show_image(inference_result)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
